{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e346834-7ee6-4107-a4f0-9999f79dad34",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Influencing the Narrative: Sentiment Analysis of Donald Trump's Tweets\"\n",
    "description: \"Blog page for Digital Humanities 140 final project.\"\n",
    "author: \"Andrew Schweitzer\"\n",
    "date-modified: \"August 2 2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a0288f-c00e-43e6-964c-97fa29182805",
   "metadata": {},
   "source": [
    "# <h1 style=\"color: darkblue; text-align: center;\">Influencing the Narrative: Sentiment Analysis of Donald Trump's Tweets</h1>\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "<strong>Andrew Schweitzer</strong><br>\n",
    "<strong>2024-08-02</strong>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de06cf-7d53-4f43-9be5-ef585510eebc",
   "metadata": {},
   "source": [
    "## **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933c0a9-d513-4ea3-84b8-a2dd5434018d",
   "metadata": {},
   "source": [
    "**Donald Trump's frequent Twitter usage, both during and after his presidency, raises the questions: How did the sentiment of Trump's tweets impact public opinion? How has the sentiment of Trump's tweets changed over time, and are there any common themes associated with positive, neutral, and negative sentiments?**\n",
    "\n",
    "This study aims to examine and analyze Donald Trump's tweets since 2016 to answer these questions. We will explore the trends and shifts in sentiment of Trump's tweets throughout his presidency and analyze the public's reaction. We will also look for topics or themes that are frequently associated with positive, negative, or neutral sentiment in Trump's tweets through text analysis. This project seeks to provide insights into Trump's use of Twitter and how it might influence the future political landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e377c-78e1-4121-a51a-da0675b4dd52",
   "metadata": {},
   "source": [
    "## **Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69489e84-411d-40b1-bd98-89d44bff61b5",
   "metadata": {},
   "source": [
    "### The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63092622-efab-4f82-87cf-0661feb185aa",
   "metadata": {},
   "source": [
    "We will examine these topics by focusing on all of Donald Trump's tweets (including deleted tweets since September 2016) gathered on [Trump Twitter Archive](https://www.thetrumparchive.com/), a site that checks for Trump's Twitter activity every minute, entering it into a database. The site contains all of Trump's tweets since 2009. However, it only began tracking deleted tweets since September 2016, when the site was created. This dataset also contains user engagement for each of Trump's tweets such as retweets and likes. However, The tweets data selected show important information about all of Trump's tweets and the public's opinion so that we can fully analyze the Trump's and the public's sentiment. According to the Trump Twitter Archive, the site is a reputable source as it is frequently referenced by FactCheck.org, PolitiFact, Snopes, Wikipedia, and most news outlets. \n",
    "\n",
    "The dataset consists of 56,571 observations (tweets) and 9 columns. However, we will filter for tweets after Trump became elected, so the observations will decrease. After preprocessing, the 9 columns along with their data types are id (int), text (string), isRetweet (int), isDeleted (int), device (string), favorites (int), retweets (int), date (datetime), isFlagged (int). The id variable is a unique identifier for each tweet and is irrelevant for an analysis, so we will primarily use the other 8 variables in this study. The text variable contains the contents of Donald Trump's tweet. The isRetweet is a dummy variable with 0 corresponding to Trump's tweet not being a retweet and 1 corresponding to the tweet being a retweet. The isDeleted is also a dummy variable with 0 corresponding to the tweet not being deleted and 1 corresponding to the tweet being deleted. The device variable displays the type of device the tweet was published on. The favorites variable corresponds to the number of users who favorited (liked) the tweet. The retweets variable corresponds to the number of users who retweeted the tweet. The date variable is the date and time the tweet was published. The isFlagged variable is a dummy variable with 0 corresponding to the tweet not being flagged and 1 corresponding to the tweet being flagged. \n",
    "\n",
    "Link to dataset on Google Drive (Retrieved on 2024-07-29): [Trump Twitter Archive - CSV File](https://drive.google.com/file/d/1xRKHaP-QwACMydlDnyFPEaFdtskJuBa6/view)\n",
    "\n",
    "The code cells below prepare our data for analysis by preprocessing our variables and filtering tweets since November 8, 2016, when Donald Trump became officially elected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ce54b8-b85a-49eb-9d46-07c59a1ed4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ccac050-2484-4a16-b72f-4f998bdf6484",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets_01-08-2021.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l3/6v6d6ss51hs98krmhycznzt40000gn/T/ipykernel_81100/1676451676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tweets_01-08-2021.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tweets_01-08-2021.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets = pd.read_csv('tweets_01-08-2021.csv')\n",
    "tweets.drop(columns=['id'], inplace=True)\n",
    "\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b08d0-fdc5-42d6-b341-d784c0ce6875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets.isna().sum()) # check for any NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2091f62-dbd4-423e-a348-2dc236b8a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change variable types\n",
    "tweets['text'] = tweets['text'].astype('string')\n",
    "tweets['isRetweet'] = tweets['isRetweet'].replace({'f': 0, 't': 1})\n",
    "tweets['isDeleted'] = tweets['isDeleted'].replace({'f': 0, 't': 1})\n",
    "tweets['isFlagged'] = tweets['isFlagged'].replace({'f': 0, 't': 1})\n",
    "tweets['device'] = tweets['device'].astype('string')\n",
    "tweets['date'] = pd.to_datetime(tweets['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e2e7e8-9d88-4a76-b1ca-224d8391d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new variable: word count\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "tweets['word_count'] = tweets['text'].apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b9ab7-e455-4baa-b167-b3032fb58d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875bbe80-74b1-4188-8ec9-434052ab9d2a",
   "metadata": {},
   "source": [
    "Some tweets include links to pictures, videos, and other tweets, which do not contribute to the sentiment analysis in this study. To prepare our data for analysis, links from tweets have been removed. Additionally, observations that only include links have been removed from this dataset. Removing these links will help reduce noise in the dataset so that the focus remains on the actual text content of Trump's tweets. Effectively, the URLs have been removed to enhance accuracy and prevent any skewness in the sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20741d7d-c00c-45f9-b4a9-f0ed93bec209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_links(text):\n",
    "    url_pattern = r'http\\S+|www\\S+|https\\S+'\n",
    "    return re.sub(url_pattern, '', text)\n",
    "\n",
    "tweets['text'] = tweets['text'].apply(remove_links)\n",
    "tweets = tweets[tweets['text'].str.len() > 0] # remove any observations that were only URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9179a-a089-4911-8f7b-c4cecdfd9e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_full = tweets\n",
    "tweets_before = tweets[tweets['date'] < pd.Timestamp('2016-11-08')]\n",
    "tweets = tweets[tweets['date'] > pd.Timestamp('2016-11-08')] # filtered dataset on focus time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ac645-50c3-49db-8902-9ae6f2b39051",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304ab4d-c8af-4904-aeb1-dbcf3d69773a",
   "metadata": {},
   "source": [
    "After preprocessing our data, the dataset has 25,391 observations and 9 variables. We added a new int variable, word_count, which gives the total number of words in the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c58b6-b0a7-491f-8e11-af5ee485b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b86969-cd15-4162-99c2-f5a742c39f0c",
   "metadata": {},
   "source": [
    "### Analytical Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb8ec8-6e3c-4687-92cc-536447cb0c58",
   "metadata": {},
   "source": [
    "Before conducting our sentiment analysis, we will explore the data to better understand and receive context. In this study, we created various plots (scatter plots, bar charts, line charts, box plots) to explore relationships and trends in the data. Then we analyzed the visualizations to gain insights into tweet engagement, distributions, etc.\n",
    "\n",
    "For our sentiment analysis we will be using VADER (Valence Aware Dicionary and Sentiment Reasoner) which is a lexicon tool optimized for analysing sentinemtn expressed in social media. Each tweet was processed using VADER to assign a sentiment score ranging from -1 (very negative) to 1 (very positive). The scores were then analyzed to determine the distribution of sentiments, identify common words contributing to positive and negative sentiments, and examine changes in sentiment over time.\n",
    "\n",
    "By combining sentiment analysis with an exploratory data analysis, this study provides a detailed examination of Donald Trump's Twitter activity and its impact on public discourse. The findings highlight the significance of Trump's tweets in shaping public opinion and political engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0c32e-0ee7-43db-abd1-6d9ace7f3666",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430a427-08c5-4fab-aac7-dfd6034a98c9",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721dface-7308-4b19-b68d-4cc1dfa4fdd9",
   "metadata": {},
   "source": [
    "Before diving into a more focused analysis, we need to first understand our data. First, we will take a look at the summary statistics for the numerical variables. After getting an idea of the data, we can then visualize our data to further deepen our understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a2140-5ae3-478f-a54a-e67e1bd35903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e736798-9fc3-46f2-b4d0-f0c9d2c56303",
   "metadata": {},
   "source": [
    "From the summary statistics we can see there are 25,391 tweets in our dataset. After converting the isRetweeted, isDeleted, isFlagged columns to integer dummy variables, we can observe their means as percentages. About 38% of Trump's tweets are retweets, about 4% of tweets are deleted, and 1% of tweets are flagged. The summary statistics also give insight into user engagement such as favorites and retweets. On average, Trump's tweets receive 56,586 favorites with a standard deviation of 73,604. This means that his tweets vary significantly in their like counts. On average, Trump's tweets receive 16,940 retweets with a standard deviation of 14,770 retweets. Trump's tweets also widely vary in their retweet counts given by the large standard deviation. Lastly, Trump averages about 25 words per tweet with a standard deviation of around 14 words. To deepen our understanding, we will now visualize the data with plots, as graphs often convey insights more effectively than tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55436d31-65b9-45d4-9993-ccead4ac041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8442c42-69ac-4c0b-bb1c-6ca54fa7f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "# distribution of word count\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(tweets['word_count'], bins=20, edgecolor='black', color = '#ff4137')\n",
    "plt.title('Distribution of Word Counts in Tweets')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947e7681-8f2e-480f-9d56-82e270b4aa6b",
   "metadata": {},
   "source": [
    "This histogram displays the frequency distribution of word counts in Donald Trump's tweets. In this graph, the x-axis represents the word count of Trump's tweets and the y-axis represents the frequency of tweets for each word count range. The main takeaway from this graph is that most of Trump's tweets contain around 20 to 25 words and there is a steep drop off after. However, it is interesting that there is a small peak centered at around 45 words. This graph suggests that Trump's tweets are generally concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340b1ea-37c6-4068-a0dd-8b5208aab44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plots of engagement metrics\n",
    "data_long = pd.melt(tweets[['favorites', 'retweets']], var_name='Metric', value_name='Count')\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))\n",
    "\n",
    "# box plot\n",
    "sns.boxplot(x='Metric', y='Count', data=data_long, color = '#ff4137', ax=axs[0])\n",
    "axs[0].set_title('Distribution of Likes and Retweets (In Millions)')\n",
    "axs[0].set_xlabel('Metric')\n",
    "axs[0].set_ylabel('Count')\n",
    "\n",
    "# zoomed box plot\n",
    "sns.boxplot(x='Metric', y='Count', data=data_long, color = '#ff4137', ax=axs[1])\n",
    "axs[1].set_title('Zoomed Distribution of Likes and Retweets')\n",
    "axs[1].set_xlabel('Metric')\n",
    "axs[1].set_ylabel('Count')\n",
    "\n",
    "axs[1].set_ylim(data_long['Count'].quantile(0.01), data_long['Count'].quantile(0.99))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26cbf3b-787a-4822-899e-dfd5fbe3ed0e",
   "metadata": {},
   "source": [
    "The graph on the left illustrates a set of box plots representing favorites and retweets; however, the boxes are squished because of the amount of outliers. We can see that there are some tweets with over a million likes. So, the right plot aims to better illustrate the distribution by showing the graph from the left, but on a smaller scale. This zoomed in plot lets us take a closer look at the majority of the data. We can observe from the box plots that there is a high level of variability in user engagement, with a significant number of outliers indicating some of Donald Trump's tweets recieved disproportionately high interactions. Lastly, the median likes are retweets are much less than the maximum values, showing most tweets receiving moderate engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442946db-e2f5-4164-acc8-f6b6eff7516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet frequency graph over time\n",
    "tweets.set_index('date', inplace=True)\n",
    "monthly_tweet_counts = tweets.resample('M').size() # aggregate monthly tweets\n",
    "monthly_tweet_counts = monthly_tweet_counts.reset_index()\n",
    "monthly_tweet_counts.columns = ['Date', 'Tweet_Count']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='Date', y='Tweet_Count', data=monthly_tweet_counts, marker='o', color='#ff4137')\n",
    "\n",
    "plt.title('Total Tweet Frequency Over Time (Monthly)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Number of Tweets', fontsize=14)\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(nbins=12)) \n",
    "plt.gcf().autofmt_xdate()  # rotate labels\n",
    "plt.show()\n",
    "tweets = tweets.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa86936-6dc9-46c5-9101-c65f7979456b",
   "metadata": {},
   "source": [
    "Here is a line graph that tracks the total number of tweets Trump published each month starting from November 2016 to January 2021. In this graph the x-axis represents the date of tweet posting and the y-axis shows the number of tweets per month. We can see in the graph that there are peaks in tweet frequency throughout 2020. There is a general upward trend where tweet frequency picks up heavily in 2019 and peaks in 2020. This trend suggests Trump's tweeting activity escalated immensely due to significant political events and crises (COVID-19). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5af177-5464-49e1-9210-a47609f56c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['date'] = pd.to_datetime(tweets['date'])\n",
    "\n",
    "# Set 'date' as the index\n",
    "tweets.set_index('date', inplace=True)\n",
    "\n",
    "# Aggregate duplicates and count tweets and retweets\n",
    "tweets_aggregated = tweets.groupby([pd.Grouper(freq='D')]).agg({\n",
    "    'isRetweet': 'sum',  # Sum retweets\n",
    "    'text': 'count'      # Count tweets\n",
    "}).rename(columns={'isRetweet': 'Retweets', 'text': 'Tweets'})\n",
    "\n",
    "# Resample by month\n",
    "monthly_tweet_counts = tweets_aggregated.resample('M').sum().reset_index()\n",
    "\n",
    "# Create a 'Type' column for plotting\n",
    "monthly_tweet_counts_melted = pd.melt(monthly_tweet_counts, id_vars=['date'], \n",
    "                                      value_vars=['Tweets', 'Retweets'], \n",
    "                                      var_name='Type', value_name='Count')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.lineplot(data=monthly_tweet_counts_melted, x='date', y='Count', hue='Type', marker='o', palette=['#003366', '#66B2FF'])\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Tweet and Retweet Frequency Over Time (Monthly)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Number', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f97d82-7254-4826-9021-98d30c4280d7",
   "metadata": {},
   "source": [
    "This is a line chart that illustrates the number of tweets and retweets per month from late 2016 to early 2021. Both tweets and retweets follow the same general pattern of an overall increasing trend over time. This indicates growing activity and engagement on Donald Trump's Twitter. We can observe notable spikes at various points, suggesting specific events that lead to higher Twitter activity. We can also see that the number of tweets is consistently exceeding the number of retweets meaning that Trump's original tweets were usually more frequent than his retweets. There is a huge  spike on this graph in late 2020 which corresponds with the U.S. presidential election period. We can see the activity sharply decline in early 2021 which corresponds to Trump's Twitter ban in January 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc72b8-1ed8-46d2-9a1f-4da2d2d6b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.reset_index()\n",
    "tweets['day_of_week'] = tweets['date'].dt.day_name()\n",
    "tweet_counts = tweets['day_of_week'].value_counts()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "tweet_counts_df = tweet_counts.reindex(day_order).reset_index()\n",
    "tweet_counts_df.columns = ['Day of Week', 'Tweet Count']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Day of Week', y='Tweet Count', data=tweet_counts_df, color = '#66B2FF')\n",
    "plt.title('Tweet Frequency by Day of the Week')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356766d7-8f1a-4753-a39b-37080030f80a",
   "metadata": {},
   "source": [
    "This is a bar chart which shows the total number of tweets posted by Donald Trump on each day of the week. There is not much variation among the days of the week, but we can see that Trump tweeted most frequently on Tuesday, Wednesday, and Friday. We can see dips in activity on Thrusday, Sunday, and Monday indicating that Trump is most active in the middle of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce977f-2b50-43cc-b73b-7529cf4c562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=tweets, x='favorites', y='retweets', alpha=0.5, color = '#003366')\n",
    "plt.title('Likes vs. Retweets')\n",
    "\n",
    "plt.xlim(tweets['favorites'].quantile(0.01), tweets['favorites'].quantile(0.99))\n",
    "plt.ylim(tweets['retweets'].quantile(0.01), tweets['retweets'].quantile(0.99))\n",
    "\n",
    "plt.xlabel('Likes')\n",
    "plt.ylabel('Retweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ea66ba-8eaf-454a-814b-e6c1c1ef7f9d",
   "metadata": {},
   "source": [
    "This graph is a scatter plot which compares the number of favorites to the number of retweets for Donald Trump's tweets. Overall, we see a positive correlation between likes and retweets. We see from the distribution that there is a dense concentration at lower values, indicating that most tweets have fewer likes and retweets. The spread widens as the number of likes increases and we can observe that the relationship between likes and retweets for tweets with high engagement become more variable. We can see data points for tweets with 0 likes because these are Donald Trump's retweets which can not receive likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff24bdb-7d92-470b-a345-4f7e251a1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_texts = ' '.join(tweets['text'].dropna())\n",
    "hashtags = re.findall(r'#\\w+', all_texts)\n",
    "hashtag_counts = Counter(hashtags)\n",
    "top_hashtags_df = pd.DataFrame(hashtag_counts.most_common(10), columns=['Hashtag', 'Count'])\n",
    "\n",
    "plt.figure(figsize=(12, 8)) \n",
    "ax = plt.gca()  # Get current Axes\n",
    "top_hashtags_df.plot(kind='bar', x='Hashtag', y='Count', legend=False, color='#ff4137', ax=ax)\n",
    "\n",
    "plt.title('Top 10 Hashtags')\n",
    "plt.xlabel('Hashtag')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416e242-d9f6-4eca-aa20-9fd93d1acf7c",
   "metadata": {},
   "source": [
    "Here is a graph showing the most frequent hashtags Donald Trump used in his tweets. The main hashtag that Donald Trump used was his slogan, MAGA (Make America Great Again). Then there is a steep decline in frequency for other hashtags.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff5cf6-c70a-4628-be04-29303f03222f",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a443cd-0c71-4300-809e-36331cf237a5",
   "metadata": {},
   "source": [
    "After gaining a better understanding of our data, we can now move on to analyzing the sentiment of Donald Trump's tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca3198f-bff3-456f-91da-c9999f53aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "from matplotlib.colors import Normalize, TwoSlopeNorm\n",
    "from matplotlib.cm import ScalarMappable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b931749a-637d-42e3-bf94-12c5e3dc2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "def get_sentiment_score(text):\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    return sentiment['compound']  # compound score: overall sentiment\n",
    "\n",
    "tweets['sentiment_score'] = tweets['text'].apply(get_sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ae9fd-e574-4b23-a2f8-46cd805ca749",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(tweets['sentiment_score'], bins=30, kde=False, color='#003366')\n",
    "\n",
    "plt.title('Distribution of Sentiment Scores', fontsize=16)\n",
    "plt.xlabel('Sentiment Score', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.xlim(-1, 1)  # Sentiment scores range from -1 to 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d023f2-c43e-4c8f-9883-e3a64598c666",
   "metadata": {},
   "source": [
    "This histogram depicts the frequency of sentiment scores computed from Donald Trump's tweets. Sentiment scores range from -1 (very negative) to 1 (very positive). The highest bar is at the sentiment score of 0, indicating neutral sentiment. A significant portion of Trump’s tweets are neutral, as indicated by the peak at 0. There is a notable spread of sentiment scores across the spectrum, with a relatively even distribution of both positive and negative sentiments. However, we can see a slight bias towards the positive sentiment score with more tweets being positive than negative. This suggests that Trump's tweets vary widely in tone, from very positive to very negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb240526-46b8-4d32-b3d5-d5c939140d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_words = [word for word in tokens if word not in stop_words and word.isalnum()]\n",
    "    return filtered_words\n",
    "\n",
    "# Function to get sentiment\n",
    "def get_sentiment(word):\n",
    "    score = sid.polarity_scores(word)\n",
    "    if score['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Combine all text data\n",
    "all_texts = ' '.join(tweets['text'])\n",
    "words = preprocess_text(all_texts)\n",
    "\n",
    "# Get sentiment for each word\n",
    "positive_words = [word for word in words if get_sentiment(word) == 'positive']\n",
    "negative_words = [word for word in words if get_sentiment(word) == 'negative']\n",
    "\n",
    "# Count frequency\n",
    "positive_freq = nltk.FreqDist(positive_words)\n",
    "negative_freq = nltk.FreqDist(negative_words)\n",
    "\n",
    "# Most common words\n",
    "most_common_positive = positive_freq.most_common(10)\n",
    "most_common_negative = negative_freq.most_common(10)\n",
    "\n",
    "# Prepare data for plotting\n",
    "pos_words = [word for word, count in most_common_positive]\n",
    "pos_counts = [count for word, count in most_common_positive]\n",
    "neg_words = [word for word, count in most_common_negative]\n",
    "neg_counts = [count for word, count in most_common_negative]\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(14, 7))\n",
    "\n",
    "# Negative words\n",
    "axes[0].barh(neg_words, neg_counts, color='salmon')\n",
    "axes[0].set_xlabel('Contribution to Sentiment')\n",
    "axes[0].set_title('10 Most Common Negative Words')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Positive words\n",
    "axes[1].barh(pos_words, pos_counts, color='#77d6b1')\n",
    "axes[1].set_xlabel('Contribution to Sentiment')\n",
    "axes[1].set_title('10 Most Common Positive Words')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98fd050-4c7a-46da-a533-f6de22f038ed",
   "metadata": {},
   "source": [
    "These bar charts highlight the ten most frequently used positive and negative words in Trump's tweets that contribute to positive and negative sentiment. Each bar in the bar chart represents the frequency of a specific word and we can see that negative words such as \"fake,\" \"bad,\" \"crime\" dominate the list. These are most likely associated with Donald Trump's criticisms and negative remarks. These words suggest why his tweets have been known to receive polarizing reactions from the public. Positive words like \"great\", \"thank\", and \"want\" are his most prevalent positive words. These words can be associated to his gratitude, possibly from winning the election. This makes sense because while he was campaigning, he used \"great\" numerous times to get his message across (MAGA). The frequent use of these positive words suggest that Trump used Twitter in an attempt to foster a positive image throughout his presidency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c8cac-e5b8-4939-9a09-520ee1b0d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['year_month'] = pd.to_datetime(tweets['date']).dt.to_period('M')\n",
    "monthly_sentiment = tweets.groupby('year_month')['sentiment_score'].mean()\n",
    "full_date_range = pd.period_range('2017-01', '2021-12', freq='M')\n",
    "monthly_sentiment = monthly_sentiment.reindex(full_date_range, fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "cmap_positive = plt.get_cmap('Greens')\n",
    "cmap_negative = plt.get_cmap('Reds')\n",
    "norm = TwoSlopeNorm(vmin=-0.0001, vcenter=0, vmax=monthly_sentiment.max())\n",
    "\n",
    "colors = [cmap_positive(norm(value)) if value > 0 else cmap_negative(norm(value)) for value in monthly_sentiment.values]\n",
    "bars = ax.bar(monthly_sentiment.index.astype(str), monthly_sentiment.values, color=colors)\n",
    "\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Average Sentiment Score')\n",
    "ax.set_title('Average Sentiment Score by Month (2017-2021)')\n",
    "ax.set_xticks([f'{year}-01' for year in range(2017, 2022)])\n",
    "ax.set_xticklabels([f'Jan {year}' for year in range(2017, 2022)])\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax.set_xlim(-0.5, len(monthly_sentiment) - 0.5)\n",
    "sm_positive = ScalarMappable(cmap=cmap_positive, norm=norm)\n",
    "sm_positive.set_array([0, 1])\n",
    "cbar_positive = fig.colorbar(sm_positive, ax=ax, orientation='vertical', label='Positive Sentiment Score', pad=0.02, fraction=0.04)\n",
    "cbar_positive.ax.set_position([0.93, 0.15, 0.02, 0.7])  \n",
    "\n",
    "sm_negative = ScalarMappable(cmap=cmap_negative, norm=norm)\n",
    "sm_negative.set_array([-1, 0])\n",
    "cbar_negative = fig.colorbar(sm_negative, ax=ax, orientation='vertical', label='Negative Sentiment Score', pad=0.02, fraction=0.04)\n",
    "cbar_negative.ax.set_position([0.90, 0.15, 0.02, 0.7]) \n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1.5, 1])  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc532b6-0843-41a8-961c-bf0efaa9b0d4",
   "metadata": {},
   "source": [
    "This bar chart displays the average sentiment score of Trump’s tweets for each month from 2017 to early 2021. The color intensity represents the sentiment score, with darker shades indicating higher sentiment. There are noticeable fluctuations in average sentiment scores over the year; however, his monthly tweets are consistently positive throughout his presidency. For example, mid-2018 shows a significant positive peak, while early 2021 shows a decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680fc86e-ecf1-4ff8-8ed5-aeba6a804469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# favorites\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='sentiment_score', y='favorites', data=tweets[tweets['favorites'] > 0], scatter_kws={'s':10}, line_kws={'color':'red'}, color = '#003366')\n",
    "plt.title('Sentiment Score vs. Favorites')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Number of Favorites')\n",
    "plt.ylim(tweets['favorites'].quantile(0.01), tweets['favorites'].quantile(0.99))  \n",
    "plt.show()\n",
    "\n",
    "# retweets\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='sentiment_score', y='retweets', data=tweets, scatter_kws={'s':10}, line_kws={'color':'red'}, color = '#66B2FF')\n",
    "plt.title('Sentiment Score vs. Retweets')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Number of Retweets')\n",
    "plt.ylim(tweets['retweets'].quantile(0.01), tweets['retweets'].quantile(0.99))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944d6f7-1280-40fb-90ca-9b37c20110d2",
   "metadata": {},
   "source": [
    "The scatter plots illustrate the relationship between sentiment scores and engagement metrics (retweets and favorites). Each dot represents a tweet, plotted based on its sentiment score and the number of retweets (top) or favorites (bottom). Both scatter plots suggest a slight negative correlation between sentiment score and engagement. Tweets with more neutral or slightly negative sentiment tend to receive more retweets and favorites. This could suggest why Donald Trump is more well known as being negative because his tweets with negative sentiment receive more engagement and are emphasized to the public. This trend could indicate that tweets with a balanced or controversial tone resonate more with the public, leading to higher engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a21e7e-77f5-4979-82ea-b229158ace89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=tweets, x='device', y='sentiment_score', color = '#ff4137')\n",
    "plt.title('Sentiment Distribution by Device Type')\n",
    "plt.xlabel('Device Type')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c436e5ea-0382-4a82-b10b-26e2cb2267a9",
   "metadata": {},
   "source": [
    "The box plot shows the distribution of sentiment scores for Trump’s tweets, categorized by the device used to post them. Each box represents the interquartile range (IQR) with the median indicated by a line. The sentiment distribution varies significantly by device. For instance, tweets from the \"Twitter Web Client\" exhibit the most negative sentiment, while those from \"Media Studio\" tend to be more positive. However, they are consistently positive regardless of device. This variance might reflect the context or intent behind the tweets, with certain devices being used for specific types of messaging (official statements vs. personal opinions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc4eb2-2a48-4cc3-b8cc-2aa0a64ccf16",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c358d3c-b394-470e-95fa-a129634bbb03",
   "metadata": {},
   "source": [
    "⁤After analyzing the data we can come to the conclusion that Donald Trump's frequent Twitter activity has had a huge impact on the public and politics. ⁤⁤Several takeaways found in this analysis include: ⁤\n",
    "\n",
    "⁤The sentiment scores for Donald Trump's tweets vary widely from positive to negative. ⁤⁤As a result, we can observe a strong reaction from the public. ⁤⁤Interestingly, Donald Trump received the most engagement on tweets that were neutral or slightly negative. ⁤⁤This could explain why we always hear about Trump's outrageous tweets since the controversial tweets catch more attention. ⁤These shifts in sentiment over time reflect the dynamic nature of Trump's presidency and the corresponding public response. Notable events, such elections, policy announcements, or major scandals, likely drove these changes in sentiment.\n",
    "\n",
    "The analysis of common positive and negative words provides insight into the themes associated with different sentiments. Negative words such as \"fake,\" \"bad,\" and \"weak\" suggest a focus on criticism and conflict, while positive words like \"great,\" \"thank,\" and \"win\" highlight achievements and gratitude. These themes are consistent with Trump's communication style, which often involves strong language and direct engagement with his audience, whether in praise or criticism."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
